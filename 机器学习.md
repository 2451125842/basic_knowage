# 机器学习 Machine Learning

## 引言

- 机器学习最初的定义（Defined by Arthur Samuel in 1959）

  Machine Learning is Fields of study that gives computers the ability to learn without bing explicitly programmed（显著式编程）

  所谓显著式编程，就是不明确的写出输入信息的处理逻辑，通过大量正确的输入与输出让计算机自己总结规律，最终得出最合适的逻辑

- 收益函数（Reward function）：通过定义一些列行为并根据环境对这一系列行为的收益进行规定，即为收益函数。

  非显著式编程仅仅编写收益函数，然后由计算机自己进行归纳总结，寻找收益最大的行为。即，非显著式编程通过数据、经验自动的让计算机学习，最终完成我们交给的任务。

- 机器学习目前公认的定义（Defined by Tom Mitshell in 1998 --《MachineLearning》）

  A computer program is said to learn from experience E with respect to some task T and some performance measure P， if its performance on T，as measured by P，improves with experience E.

  一个计算机程序被称为可以学习，是指它能够针对某个任务T和某个性能指标P，从经验E中学习。这种学习的特点是，它在T上的被P所衡量的性能，会随着经验E的增加而提高。

### 机器学习的分类

在机器学习中，我们按照任务性质的不同，可以将机器学习方法分为监督学习和强化学习。

- 监督学习（Supervised Learning）：所有的经验E都是由人工采集并输入计算机的，输入的训练数据需要打上标签

  为训练数据打标签：告诉计算机输入数据是什么

- 强化学习（Reinforcement Learning）：经验E是由计算机与环境互动获得的，计算机产生行为同时获得这个行为的结果，我们的程序仅仅需要定义这些行为的收益函数，同时，我们需要设计算法，让计算机通过改变自己的行为模式去最大化收益函数，完成机器学习的过程。 即，计算机通过与环境的互动强化自己的行为模式

现代的机器学习对于分类以及较为模糊，很多时候强化学习中又有监督学习的算法。

监督学习根据数据标签存在与否又可分为：传统的监督学习（Traditional Supervised Learning）、非监督学习（Unsupervised Learning）和半监督学习（Semi-supervised Learning）

- 传统的监督学习：如果每一个训练数据都有对应的标签，那么该算法即位传统的监督学习算法。著名的传统监督学习算法有：支持向量机（Support Vector Machine）、人工神经网络（Neural Networks）、深度神经网络（Deep Neural Networks）等
- 非监督学习：如果所有的训练数据都没有标签，该算法即为非监督学习。著名算法有：聚类（Clustering）、EM算法（Expectation-Maximization algorithm）、主成分分析（Principle Component Analysis）等
- 半监督学习：即训练数据一部分有标签，而另一部分没有标签。

另一种分类方法，是基于标签的固有属性，可将监督学习分为分类（Classification）和回归（Regression）

- 如果标签为离散的值，我们称之为分类。e.g.：人脸识别等
- 如果标签是连续的值，我们成为回归。e.g.：预测股票、预测房价等

### 机器学习算法的过程

1. 特征提取（Feature Extraction）：通过训练样本获得的，对机器学习任务有帮助的多维度数据。

   尽管提取特征非常重要，但由于提取特征的方法繁多，对于不同任务可能需要使用不同的方法，因此机器学习过程中假设已经完成了特征提取

2. 特征选择

3. 不同的算法对特征空间做不同的划分

4. 获得不同的结果

5. 研究不同的应用场景应该采取哪种机器学习算法，以及研究新的学习算法以便适应新的场景